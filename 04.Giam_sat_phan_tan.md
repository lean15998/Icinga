# Giám sát phân tán

### 1. [Roles](#1)
### 2. [Zone](#2)
### 3. [Endpoint](#3)
### 4. [Apilistener](#4)
### 5. [Quy ước](#5)
### 6. [Master Setup](#6)
### 7. [Agent/Satellite Setup](#7)
### 8. [Chế độ cấu hình](#8)

<a name=1></a>

#  Roles

- Một node master nằm trên cùng của hệ thống phân cấp.
- Một node satellite là con của một node master.
- Một node agent được kết nối với node satellite và node master.

<img src= "https://github.com/lean15998/Icinga/blob/main/image/4.01.png" >

- Một node master không có node cha.
<ul>
  <ul>
  <li> Node master là nơi bạn thường cài đặt Icinga Web 2.
  <li> Một node master có thể thực hiện check từ các node con.
 </ul>
</ul>
  
- Một node satellite có một node cha và một node con.
<ul>
  <ul>
  <li> Một node satellite có thể tự thực hiện kiểm tra hoặc ủy quyền thực thi kiểm tra cho các node con.
  <li> Một node satellite có thể nhận cấu hình cho các host/service, v.v. từ node cha.
  <li> Một node satellite tiếp tục chạy ngay cả khi node master tạm thời không khả dụng.
  </ul>
</ul>
    
- Một node agent chỉ có một node cha.
<ul>
  <ul>
    <li> Một node agent sẽ chạy các check được cấu hình trên nó hoặc nhận lệnh từ node cha.
  </ul>
</ul>

<a name=2></a>
# Zone

- Hệ thống phân cấp Icinga2 bao gồm cái gọi là các zone object . Các zone phụ thuộc vào mối quan hệ cha parent-child tin tưởng nhau.

<img src = "https://github.com/lean15998/Icinga/blob/main/image/4.02.png">

 - VD về cấu hình các node satellite có node master là zone parent:

```sh
object Zone "master" {
   //...
}

object Zone "satellite region 1" {
  parent = "master"
  //...
}

object Zone "satellite region 2" {
  parent = "master"
  //...
}
```

- Hạn chế nhất định đối với các zone con là các thành viên của chúng không được phép gửi các lệnh cấu hình cho các thành viên zone cha. Ngược lại, hệ thống phân cấp tin cậy cho phép zone master gửi các tệp cấu hình đến zone satellite.
- Agent node cũng có zone duy nhất của riêng chúng.
<a name=3></a>
# Endpoint

- Các node là thành viên của một zone được gọi là các đối tượng endpoint.

<img src="https://github.com/lean15998/Icinga/blob/main/image/4.03.png">

- File cấu hình của 2 endpoint ở các zone khác nhau.

```sh
object Endpoint "master1" {
  host = "192.168.56.101"
}

object Endpoint "atellite1" {
  host = "192.168.56.105"
}

object Zone "master" {
  endpoints = [ "master1" ]
}

object Zone "satellite" {
  endpoints = [ "satellite1" ]
  parent = "master"
}
```

<a name=4></a>
# Apilistener

- Trong trường hợp sử dụng các lệnh CLI sau này, bạn không cần phải viết lại cấu hình. Đối tượng ApiListener được sử dụng để tải chứng chỉ TLS và chỉ định các hạn chế, ví dụ: chấp nhận các lệnh cấu hình.
- Nó cũng được sử dụng cho Icinga 2 REST API chia sẻ cùng một host và port với giao thức Icinga 2 Cluster.
- Cấu hình object được lưu trữ trong tệp `/etc/icinga2/features-enabled/api.conf`. Tùy thuộc vào chế độ cấu hình, các thuộc tính `accept_commands` và `accept_config` có thể được cấu hình ở đây.
- Mở tính năng api.

```sh
icinga2 feature enable api
```
<a name=5></a>
# Quy ước

- Theo quy ước, tất cả các node phải được cấu hình bằng FQDN của chúng.

- Hơn nữa, phải đảm bảo rằng các tên sau đây hoàn toàn giống nhau trong tất cả các tệp cấu hình:
<ul>
  <ul>
  <li> Tên chung của chứng chỉ máy chủ (CN).
  <li> Đối tượng cấu hình endpoint cho host.
  <li> Hằng số NodeName cho localhost.
  </ul>
</ul>

<a name=6></a>
# Master Setup

- Cách cài đặt một node master bằng lệnh `node wizard`.

- Chạy lệnh CLI `node wizard`. Trước đó, hãy đảm bảo thu thập thông tin cần thiết:

| Tham số |	Mô tả |
| -- | -- |
| Common name (CN)	| (Yêu cầu) Theo quy ước, đây phải là FQDN của máy chủ. Mặc định là FQDN. |
| Master zone name |	(Không bắt buộc) Cho phép chỉ định tên zone master. Mặc định là master |
| Global zones	| (Không bắt buộc) Cho phép chỉ định nhiều zone global hơn ngoài global-templates và director-global. Mặc định là `N`. |
| API bind host |	(Không bắt buộc) Cho phép chỉ định địa chỉ mà ApiListener bị ràng buộc. Chỉ dành cho mục đích sử dụng nâng cao. |
| API bind port |	(Không bắt buộc) Cho phép chỉ định cổng mà ApiListener bị ràng buộc. Chỉ để sử dụng nâng cao (cổng mặc định 5665). |
| Disable conf.d |	(Không bắt buộc) Cho phép vô hiệu hóa include_recursive "conf.d"chỉ thị ngoại trừ tệp api-users.conf trong tệp icinga2.conf. Mặc định là `Y`. |


- Trình `wizard` sẽ đảm bảo rằng các bước sau được thực hiện:


<ul>
  <ul>
  <li> Bật tính năng api.
  <li> Tạo một tổ chức phát hành chứng chỉ (CA) mới /var/lib/icinga2/ca nếu nó không tồn tại.
  <li> Tạo chứng chỉ cho node được ký bởi khóa CA.
  <li> Cập nhật tệp zone.conf với cấu trúc phân cấp zone mới.
  <li> Cập nhật cấu hình ApiListener và constant .
  <li> Cập nhật icinga2.conf để tắt tệp conf.d và thêm tệp api-users.conf.



## Signing Certificates on the Master 

- Tất cả các chứng chỉ phải được ký bởi cùng một tổ chức phát hành chứng chỉ (CA). Điều này đảm bảo rằng tất cả các node tin cậy lẫn nhau trong một môi trường giám sát phân tán.

- CA này được tạo trong quá trình thiết lập master và phải giống nhau trên tất cả master instances.

- Có thể ký và triển khai chứng chỉ theo cách thủ công bằng cách sử dụng các phương pháp tích hợp sẵn cho các yêu cầu ký chứng chỉ tự động ký (CSR):

<ul>
  <ul>
    <li> CSR Auto-Signing:  sử dụng client (satellite hoặc agent) ticket được tạo trên master làm định danh tin cậy.
    <li> On-Demand CSR Signing: cho phép ký các yêu cầu chứng chỉ đang chờ xử lý trên master.
    </ul>
 </ul>

### CSR Auto-Signing 

- Một client có thể là master, satellite hoặc agent. Nó gửi một yêu cầu ký chứng chỉ (CSR) và phải tự xác thực theo cách đáng tin cậy. Master tạo một ticket client bao gồm trong request này. Bằng cách đó, master có thể xác minh rằng request khớp với ticket tin cậy trước đó và ký vào request.

Ưu điểm:

- Các node (master, satellite, agent) có thể được cài đặt bởi những người dùng khác nhau đã nhận được ticket client.
- Không cần tương tác thủ công trên node master.

Nhược điểm:

- Các ticket cần được tạo trên master và được sao chép vào các trình wizard của client.
- Không có trung tâm quản lý chữ ký.
    
### Chuẩn bị
- Trước khi sử dụng chế độ này, hãy đảm bảo rằng các bước sau được thực hiện ký trên master:

   <ul>
     <ul>
      <li> Thiết lập master được chạy thành công. Bao gôm:(Đã tạo một cặp khóa CA), (Đã tạo salt ticket bí mật được lưu trữ trong hằng số TicketSalt , được đặt làm thuộc tính ticket_salt bên trong tính năng api .)
      <li> Khởi động lại master.
     </ul>
   </ul>
    
### Trên Master
    
- Trình wizard cho các node satellite/agent sẽ yêu cầu bạn cung cấp ticket client.

- Có hai cách có thể để lấy lại ticket:

 <ul>
     <ul>
      <li> Lệnh CLI được thực thi trên node master.
      <li> Yêu cầu API REST đối với node master.
     </ul>
   </ul>

- Thông tin bắt buộc
    
| Tham số	| Mô tả |
| -- | -- |    
| Common name (CN) |	(Yêu cầu) Tên của  agent/satellite. (là FQDN) |
    
    
- Tạo một ticket trên node master(master1) cho agent(agent1):

```sh
  [root@master1 /]# icinga2 pki ticket --cn "agent1"
```
- Truy vấn Icinga2 API trên master yêu cầu đối tượng ApiUser có ít nhất quyền actions/generate-ticket.

```sh
[root@master1 /]# vim /etc/icinga2/conf.d/api-users.conf

object ApiUser "client-pki-ticket" {
  password = "bea11beb7b810ea9ce6ea" //change this
  permissions = [ "actions/generate-ticket" ]
}

[root@master1 /]# systemctl restart icinga2

Retrieve the ticket on the master node `icinga2-master1.localdomain` with `curl`, for example:

 [root@master1 /]# curl -k -s -u client-pki-ticket:bea11beb7b810ea9ce6ea -H 'Accept: application/json' \
 -X POST 'https://localhost:5665/v1/actions/generate-ticket' -d '{ "cn": "icinga2-agent1.localdomain" }'
 ```

- Lưu trữ ticket đó cho satellite/agent để thiết lập sau này.



### On-Demand CSR Signing

- Tìm hiểu sau.
    
<a name=7></a>    
    
# Agent/Satellite Setup

- Tạo một ticket trên node master(master1) cho agent(agent1):
 ```sh
[root@master1 /]# icinga2 pki ticket --cn "agent1"
4f75d2ecd253575fe9180938ebff7cbca262f96e
```
- Chạy "node wizard" và nhập theo yêu cầu các thông số sau
    
    ```sh
    [root@agent1 /]# icinga2 node wizard
    ```
    
<ul>
  <ul>
    <li> Common name (CN)
    <li>  Master/Satellite Common Name
    <li> Master/Satellite endpoint host
    <li> Master/Satellite endpoint port
    <li> Ticket 
  </ul>
  </ul>
        
 - Restart dịch vụ icinga2
    
```sh
[root@agent1 /]# systemctl restart icinga2
```
      
- Tổng quan về tất cả các thông số:
    
| Tham số | Mô tả |
|  -- | -- |
| Common name (CN)	| (Yêu cầu) Theo quy ước, đây phải là FQDN của máy chủ. Mặc định là FQDN. |
| Master common name	| (Yêu cầu) Sử dụng tên chung mà bạn đã chỉ định cho node master. |
| Establish connection to the parent node	| (Không bắt buộc) Liệu node có cố gắng kết nối với node cha hay không. Mặc định là y. |
| Master/Satellite endpoint host |	Bắt buộc nếu agent cần kết nối với master/satellite. Địa chỉ IP của master endpoint hoặc FQDN. Thông tin này được bao gồm trong cấu hình Endpoint trong tệp zones.conf. |
| Master/Satellite endpoint port	| Tùy chọn nếu agent cần kết nối với master/satellite. Port lắng nghe của thiết bị master endpoint. Thông tin này được bao gồm trong caus hình đối tượng Endpoint. |
| Add more master/satellite endpoints	| (Không bắt buộc) Nếu muốn cấu hình nhiều node master/satellite |
| Parent Certificate information	| (Yêu cầu) Xác minh node master. |
| Request ticket	| (Không bắt buộc) Thêm ticket được tạo trên node master. |
| API bind host	| (Không bắt buộc) Cho phép chỉ định địa chỉ mà ApiListener bị ràng buộc. |
| API bind port	| (Không bắt buộc) Cho phép chỉ định cổng mà ApiListener bị ràng buộc (mặc định 5665). |
| Accept config	| (Không bắt buộc) Chấp nhận đồng bộ cấu hình từ node master (bắt buộc đối với chế độ đồng bộ cấu hình ). Vì lý do bảo mật ,nên mặc định là n. |
| Accept commands	| (Không bắt buộc) Chấp nhận thông báo thực thi lệnh từ node maste (bắt buộc đối với chế độ command endpoint ). Vì lý do bảo mật ,nên mặc định là n. |
| Local zone name	| (Không bắt buộc) Cho phép chỉ định tên cho local zone. Mặc định là FQDN.  |
| Parent zone name	| (Không bắt buộc) Cho phép chỉ định tên cho parent zone. Mặc định là master. |
| Global zones	| (Không bắt buộc) Cho phép chỉ định nhiều global hơn ngoài global-templates và director-global. Mặc định là n. |
| Disable conf.d	| (Không bắt buộc) Cho phép vô hiệu hóa thư mục conf.d chứa cấu hình cục bộ. Client nên truy xuất cấu hình của họ từ node cha hoặc hoạt động như cầu nối thực thi command endpoint. Mặc định là y. |
      
 - Đảm bảo rằng các bước sau được thực hiện:
    <ul>
      <ul>
        <li> Bật tính năng api.
         <li> Tạo yêu cầu ký chứng chỉ (CSR) cho node local.
          <li> Yêu cầu chứng chỉ đã ký (tùy chọn với số vé được cung cấp) trên node master.
           <li> Cho phép xác minh chứng chỉ của node cha.
            <li> Lưu trữ chứng chỉ satellite/agent đã ký và ca.crt vào /var/lib/icinga2/certs.
            <li> Cập nhật tệp  zones.conf với hệ thống phân cấp zone mới.
            <li> Cập nhật /etc/icinga2/features-enabled/api.conf( accept_config, accept_commands) và constants.conf.
            <li> Cập nhật /etc/icinga2/icinga2.conf và comment include_recursive "conf.d".
      </ul>
    </ul>
      
- Bạn có thể kiểm tra các tệp chứng chỉ được lưu trữ trong thư mục `/var/lib/icinga2/certs`.
      
 <a name=8></a>     
      
 # Chế độ cấu hình
    
 ### Top Down Command Endpoint
    
- Chế độ này node Icinga2 thực hiện các lệnh từ xa trên một endpoint được chỉ định. Cấu hình objecct host/service được đặt trên master/satellite và agent chỉ cần các định nghĩa CheckCommand object có sẵn.
- Mỗi endpoint đều có check queue từ xa của riêng nó. Số lượng kiểm tra được thực hiện đồng thời có thể bị giới hạn trên endpoint với hằng số `MaxConcurrentChecks` được xác định trong file  `constants.conf` . Icinga 2 có thể hủy yêu cầu kiểm tra nếu check queue từ xa đã đầy.

<img src= "https://github.com/lean15998/Icinga/blob/main/image/4.0.4.png" >

- Ưu điểm:
<ul>
  <ul>
  <li> Không cần xác định kiểm tra cục bộ trên node con (agent).
  <li> Thực thi check từ xa  (sự kiện không đồng bộ).
  <li> Không cần relay log cho node con.
  <li> Pin check các endpoint cụ thể (nếu zone con bao gồm 2 endpoint).
  </ul>
</ul>
    
- Nhược điểm:
<ul>
  <ul>
  <li> Nếu node con không được kết nối, không có check nào được thực hiện nữa.
  <li> Yêu cầu thuộc tính cấu hình bổ sung được chỉ định trong các object host/service.
  <li> Yêu cầu cấu hình đối tượng CheckCommand cục bộ. Cách tốt nhất là sử dụng global zone.
  </ul>
</ul>
    
- Để đảm bảo rằng tất cả các node có liên quan sẽ chấp nhận cấu hình hoặc lệnh, bạn cần  cấu hình phân cấp Zone và Endpoint trên tất cả các node.

    VD:
    <ul>
  <ul>
  <li> master1 là cấu hình master trong trường hợp này.
  <li> agent1 hoạt động như một agent nhận thông báo thực thi lệnh thông qua endpoint từ master. Ngoài ra, nó nhận cấu hình global check command từ master.
  </ul>
</ul>
    
- Ví dụ về cấu hình endpoint
    
```sh
[root@agent1 /]# vim /etc/icinga2/zones.conf

object Endpoint "master1" {
  host = "192.168.56.101"
}

object Endpoint "agent1" {
  host = "192.168.56.111"
  log_duration = 0 // Disable the replay log for command endpoint agents
}
```
      
- Xác định 2 zone 
    
 ```sh
    [root@agent1 /]# vim /etc/icinga2/zones.conf

object Zone "master" {
  endpoints = [ "master1" ] //array with endpoint names
}

object Zone "agent1" {
  endpoints = [ "agent1" ]

  parent = "master" //establish zone hierarchy
}
 ```
- Không cần bất kỳ cấu hình cục bộ nào trên agent ngoại trừ các định nghĩa CheckCommand có thể được đồng bộ hóa bằng cách sử dụng global zone. Do đó, hãy vô hiệu hóa việc đưa thư mục `conf.d` vào `/etc/icinga2/icinga2.conf`.

 ```sh
 [root@agent1 /]# vim /etc/icinga2/icinga2.conf

// Commented out, not required on an agent as command endpoint
//include_recursive "conf.d"
 ```
    
- Xác thực cấu hình và khởi động lại daemon icinga2 trên cả 2 node   
    
 ```sh
[root@agent1 /]# icinga2 daemon -C
[root@agent1 /]# systemctl restart icinga2

[root@master1 /]# icinga2 daemon -C
[root@master1 /]# systemctl restart icinga2
```
 
- Thực hiện cấu hình check từ xa agent bằng cách sử dụng endpoint
    
 ```sh
[root@master1 /]# mkdir -p /etc/icinga2/zones.d/master
[root@master1/]# cd /etc/icinga2/zones.d/master
[root@master1 /etc/icinga2/zones.d/master]# vim hosts.conf

object Host "agent1" {
  check_command = "hostalive" //check is executed on the master
  address = "192.168.56.111"

  vars.agent_endpoint = name //follows the convention that host name == endpoint name
}
    
[root@master1 /etc/icinga2/zones.d/master]# vim services.conf

apply Service "disk" {
  check_command = "disk"

  // Specify the remote agent as command execution endpoint, fetch the host custom variable
  command_endpoint = host.vars.agent_endpoint

  // Only assign where a host is marked as agent endpoint
  assign where host.vars.agent_endpoint
}    
```
- Nếu tự tạo Checkcommand hãy để nó vào global zone

 ```sh 
[root@master1 /]# mkdir -p /etc/icinga2/zones.d/global-templates
[root@master1 /]# vim /etc/icinga2/zones.d/global-templates/commands.conf

object CheckCommand "my-cmd" {
  //...
}
 ```
    
- Các bước sẽ xảy ra:
<ul>
  <ul>
<li> Icinga 2 xác nhận cấu hình trên master1 và khởi động lại.
<li> Node master1 lên lịch và thực hiện check.
<li> Node agent1 nhận sự kiện lệnh thực thi với các command parameter.
<li> Node agent1 ánh xạ các parameter command tới local check command, thực hiện check cục bộ và gửi lại thông báo kết quả check.
  </ul>
    </ul>
    
 - Có thể thấy, không yêu cầu tương tác từ phía master trên agent và không cần thiết phải tải lại dịch vụ Icinga 2 trên agent.
  
    
 ### Top Down Config Sync
    
- Đồng bộ hóa các tệp cấu hình trong các zone được chỉ định. Nó rất hữu ích nếu muốn cấu hình mọi thứ trên nút master và đồng bộ hóa các satellite check (disk, memory, v.v.). Các satellite chạy local schedule của riêng chúng và sẽ gửi lại thông báo kết quả kiểm tra cho master.
  
 <img src= "https://github.com/lean15998/Icinga/blob/main/image/4.05.png" >

- Ưu điểm:
<ul>
  <ul>
  <li> Đồng bộ các tệp cấu hình từ zone parent sang zone child.
  <li> Không cần khởi động lại thủ công trên các node child vì quá trình đồng bộ hóa, xác thực và khởi động lại diễn ra tự động.
  <li> Thực thi kiểm tra trực tiếp trên bộ lập lịch của node child.
  <li> Relay log nếu kết nối bị gián đoạn (quan trọng để giữ lịch sử kiểm tra được đồng bộ, ví dụ: đối với báo cáo SLA).
  <li> Sử dụng global zone để đồng bộ hóa các template, group, v.v.
  </ul>
    </ul>
    
- Nhược điểm:

    <ul>
      <ul>
<li> Yêu cầu một thư mục cấu hình trên node master với tên của zone bên dưới /etc/icinga2/zones.d.
<li> Cần cấu hình bổ sung zone và endpoint.
<li> Relay log được sao chép khi kết nối lại sau khi mất kết nối. Điều này có thể làm tăng việc truyền dữ liệu và tạo ra tình trạng quá tải kết nối.   
      </ul>
    </ul>
    
- Để đảm bảo rằng tất cả các node đều chấp nhận cấu hình và lệnh,cần phải cấu hình phân cấp Zone và Endpoint trên tất cả các node.

- Bao gồm cấu hình endpoint và zone trên cả hai node trong tệp `/etc/icinga2/zones.conf`.
    
```sh
[root@satellite1 /]# vim /etc/icinga2/zones.conf

object Endpoint "master1" {
  host = "192.168.56.101"
}

object Endpoint "satellite1" {
  host = "192.168.56.105"
}
```
    
```sh
[root@agent2 /]# vim /etc/icinga2/zones.conf

object Zone "master" {
  endpoints = [ "master1" ] //array with endpoint names
}

object Zone "satellite" {
  endpoints = [ "satellite1" ]

  parent = "master" //establish zone hierarchy
}
```
    
 - Chỉnh sửa api feature trên satellite1 trong  tệp `/etc/icinga2/features-enabled/api.conf` và đặt `accept_config` thành true.
    
  ```sh
[root@satellite1 /]# vim /etc/icinga2/features-enabled/api.conf

object ApiListener "api" {
   //...
   accept_config = true
}
```

- Thực hiện local check trên agent bằng cách sử dụng đồng bộ cấu hình.Có thể thêm nhiều host thực hiện check các service/agent từ xa thông qua command endpoint check .
    
 ```sh
 [root@master1 /]# mkdir -p /etc/icinga2/zones.d/satellite
[root@master1 /]# cd /etc/icinga2/zones.d/satellite

[root@master1 /etc/icinga2/zones.d/satellite]# vim hosts.conf

object Host "satellite1" {
  check_command = "hostalive"
  address = "192.168.56.112"
  zone = "master" //optional trick: sync the required host object to the satellite, but enforce the "master" zone to execute the check
}
```

- Giám sát disk của agent
    
```sh
[root@master1 /etc/icinga2/zones.d/satellite]# vim services.conf

object Service "disk" {
  host_name = "icinga2-satellite1.localdomain"

  check_command = "disk"
}    
```

- Các bước sẽ xảy ra:
<ul>
  <ul>
  <li> Icinga 2 xác nhận cấu hình trên master1.
  <li> Icinga 2 sao chép cấu hình vào kho lưu trữ cấu hình zone của nó `/var/lib/icinga2/api/zones`.
  <li> Node master1 gửi một sự kiện cập nhật cấu hình đến tất cả các endpoint trong cùng một child zone.
  <li> Node satellite1 chấp nhận cấu hình và điền vào kho lưu trữ cấu hình local zone với các tệp cấu hình đã nhận.
  <li> Node satellite1 xác nhận cấu hình và tự động khởi động lại.    
  </ul>
    </ul>
